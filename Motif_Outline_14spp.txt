Methods and Thinking for Motif Discovery Project:

We have assemblies (fasta), annotation (gff), expression data (fpkm), and evolutionary relationships (poff) for all 14 paramecium aurelia spp
	Multiple assemblies/annotations, check to make sure that the strain is correct when using these data
	Multiple poff tables; all_aurelias.flipped has removed recent/WGD2 duplicates, keeping only WGD1 (this threw out a ton of data) 

First step, modify gff to include only genic regions
bash script:
#-----
#!/bin/bash
#Iterate through all Paramecium .gff's to create new table with just genes

parameciumgff=*.gff

for species in $parameciumgff
do
  	bn=`basename $species -full.gff`
        tableFile=$bn-gene.tab
        echo "$species -> $bn -> $tableFile"
        grep -P "\tgene\t" $species | cut -f 1,4,5,7,9 | cut -d ';' -f 1 > $tableFile
        sed -i 's/ID=//' $tableFile
#	cat $species | grep "   gene    " | cut -f 1,4,5,6,9 > {$species}_table
done
#-----
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Second step, collect fasta files of upstream regions for paraorthologous genes
*There are two major ways we look for motifs, one uses groups of genes we think are coregulated, one uses evolutionary relationship (paralogs/orthologs). We are going evolutionary*
This script will take the genic-gff, fasta file, and poff table as INPUTS
It will return many fasta files of 200bp upstream of each gene represented in the poff table
R script:
#-----
#source("http://bioconductor.org/biocLite.R")
#biocLite("seqinr")
#install.packages("seqinr")
library("seqinr")

extractUpstream = function(sp, geneID, lGFF, lfasta, fname){      #Pass species name, geneID, list of (modified) GFFs and list of FASTAs for that family
  
  grep_geneID = which(lGFF[[sp]]$V5 == geneID, arr.ind=TRUE)      #go into the 5th column of the GFF for the current species, return the row number which matches the current geneID
  #cat("Grep= ", grep_geneID, "\n")
  row_geneID = lGFF[[sp]][grep_geneID, ]                          #return the contents of the entire row where the above match was found
  if(row_geneID[,4] == "+"){                                      #get Gene's starting position, depending upon its strand 
    gene_start = row_geneID[,2]   
  } else{
    gene_start = row_geneID[,3]
  }
  scaf = as.character(row_geneID[,1])                             #return the name of the scaffold holding the gene 
  #cat("scaf= ", scaf, ".....", "gene start= ", gene_start, ".....", "strand= ", row_geneID[,4], "\n")
  scafSeq = as.character(lfasta[[sp]][scaf])                      #return the entire sequence of the scaffold which holds the current gene
  if(row_geneID[,4] == "+"){                                      #extract the correct upstream sequence. if +, then its just 200bp from start of gene, if -, then its 200 from end of gene
    upstream = substr(scafSeq, gene_start-200, gene_start)
  } else {
    upstream = substr(scafSeq, gene_start, gene_start+200)
    upstream = c2s(rev(comp(s2c(upstream))))                      #must reverse complement the gene on the minus strand. Seqinr has a strange way of doing this
  }
  return(upstream)
  #cat("Upstream sequence for ", geneID, "has been extracted successfully. \n")
}


getPOFFid = function(vsp, POFF, lGFF, lfasta) {                           #Pass vector of species names, POFF of family of interest, list of GFFs and FASTAs for that family
  
  for(i in 1:nrow(POFF)) {                                                #use i to iterate through each row number
    fname = paste(names(POFF[4]), "_", i, ".fasta", sep="")               #return file name based on the species name in column 4 (all POFFs have at least 6 columns)
    cat("Parsing line ", i, "\n")           #fun printed message
    vupstream = c()                                                       #create empty vector to store all upstream sequences for genes in this row
    
    for(sp in vsp) {                                                      #iterate through species names
      sp_family = as.character(POFF[i,sp])                                #get proteinIDs from each row (based on iterator) and column (based on species name which is the header)
      vsplit = strsplit(sp_family, ",")[[1]]                              #some columns have two geneIDs, must split them on the comma that separates them 
      
      for(geneID in vsplit){                                              #iterate through 1 or 2 geneIDs (if there's only 1, then it's fine too)

        
        if( (geneID != "NA")&(geneID != ".")&(geneID != "*")){                                                #only proceed if the geneID != '*' ... *'s are used when no ortho-paralog were found. It returns no upstream sequence
          cat("Now extracting sequence upstream of ", geneID, " (which is in", sp, ")\n")     #might as well remove*'s before running proceeding function                
          upstreamSeq = extractUpstream(sp, geneID, lGFF, lfasta, fname)
          cat("Sequence extracted: '", upstreamSeq, "'\n")
          vupstream[geneID] = upstreamSeq                                 #add the upstream sequence into a vector with the position given by the geneID. can easily call that position w/ geneID
        }
      }
    }
    if(length(vupstream) >= 4) {                                          #only create a fasta of these sequences if there are at least 4. MEME will not be effective with 3 or less
      writeVectorAsFasta(vupstream, fname)
      cat("line", i, "done.\n-----------------------\n")                  #print that line row is complete ... I'll keep this print-out
    }
  }
}


writeVectorAsFasta <- function(vseq, fname){                          #Pass vector of sequences from extractUpstream and name of file. This will write to fasta file as output
  #cat("FNAME: ", fname, "\n")
  cat("", file=fname)                                                 #reset the file to empty if it already exists
  #print(vseq)
  for(id in names(vseq)){                                           #iterate through geneIDs which are names for each corresponding sequence
    cat("Writing ", id ," to file '", fname, "'")
    seq_len = nchar(vseq[[id]])                                     #return length of sequence for each geneID
    
    if(seq_len > 10){                                               #only write to fasta if the length is greater than 10 (just in case something slipped by)
      cat(">", id, "\n", vseq[[id]], "\n", sep="", file=fname, append=T)       
      #write to fasta file. >geneID \n "sequence of that geneID". name the file after the species family and row number, append until this row is finished (fname will change next row)
    }
  }
}

#MAIN                                                                                 #Run in home directory, output into scratch
poff = read.table("Paramecium_POFF/all_aurelias.poff", header=T, sep="\t")
vsp = colnames(poff)[4:(ncol(poff)-1)]
lfasta = list()
lfasta[["pbi"]] = read.fasta("Paramecium_FASTA/biaurelia_V1-4_assembly_v1.fa", as.string=TRUE)          
lfasta[["ppent"]] = read.fasta("Paramecium_FASTA/ppentaurelia_mac_87_v1.0.fa", as.string=TRUE)
lfasta[["pprim"]] = read.fasta("Paramecium_FASTA/primaurelia_Ir4-2_assembly_v1.fasta", as.string=TRUE)
lfasta[["pquad"]] = read.fasta("Paramecium_FASTA/pquadecaurelia_mac_NiA_v1.0.fa", as.string=TRUE)
lfasta[["ptre"]] = read.fasta("Paramecium_FASTA/ptredecaurelia_209_AP38_filtered.fa", as.string=TRUE)
lfasta[["pnov"]] = read.fasta("Paramecium_FASTA/pnovaurelia_mac_TE_v1.0.fa", as.string=TRUE)
lfasta[["psex"]] = read.fasta("Paramecium_FASTA/sexaurelia_AZ8-4_assembly_v1.fasta", as.string=TRUE)
lfasta[["pjen"]] = read.fasta("Paramecium_FASTA/pjenningsi_mac_M_v1.0.fa", as.string=TRUE)
lfasta[["pson"]] = read.fasta("Paramecium_FASTA/psonneborni_mac_ATCC_30995_v1.0.fa", as.string=TRUE)
lfasta[["pdec"]] = read.fasta("Paramecium_FASTA/pdecaurelia_mac_223_v1.0.fa", as.string=TRUE)
lfasta[["pdodec"]] = read.fasta("Paramecium_FASTA/pdodecaurelia_mac_274_v1.0.fa", as.string=TRUE)
lfasta[["poct"]] = read.fasta("Paramecium_FASTA/poctaurelia.fasta", as.string=TRUE)
lfasta[["psept"]] =read.fasta("Paramecium_FASTA/pseptaurelia_mac_38_v1.0.fa", as.string=TRUE)
lfasta[["ptet"]] = read.fasta("Paramecium_FASTA/ptetraurelia_mac_51.fa", as.string=TRUE)

lgff = list()
for(spp in vsp){
  gff_name = paste("Paramecium_GFF/", spp, "-gene.tab", sep="")
  gff_read = read.table(gff_name, sep="\t", as.is=T)
  lgff[[spp]] = gff_read
}

getPOFFid(vsp, poff, lgff, lfasta)

#-----
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Third, we must now run meme on these sequences
Weibo and I wrote a script to submit jobs in a loop
Python script:
#-----
import os
import shutil
import re
seq = list()

file_folder = "/N/dc2/scratch/tlicknac/All_Aurelias_Upstream/"   		#Path upstream sequences

seq = os.listdir(file_folder)                         				#seq will have list of all file names

for i in seq:                                                           	#iterate through list of files
	real_i = file_folder + i
        filepath = "/N/dc2/scratch/tlicknac/All_Aurelias_MEME_Results/" +     #Location of output
        try:
            	comm1 = "mkdir " + "/N/dc2/scratch/tlicknac/All_Aurelias_MEME_Results/"                           	
        except:
               	pass
        os.system(comm1)
        comm2 = "/N/u/tlicknac/Carbonate/software/meme/install/bin/meme " + real_i + " -dna -oc " + filepath + " -nostatus -time 18000 -maxsize 60000 -nmotifs 5 -minw 5 -maxw 18"   #run my meme
        os.system(comm2)

#-----
We returned 16587 fasta files ... This is less than half of the total gene count from these organisms, but will more than due for the proceeding analysis
	These fasta files contain 4-30 sequences
	15637 files have 10 or more sequences (> ~2200 kb)
	8487 files have 20 or more sequences (> ~4350 kb) 
	1 files with 30 sequences (> ~6529 kb)
Bash command:
#-----
#Go to directory with files
find . -size +2k -ls | sort -rk7 | wc -l    #manually look at each file, figure out what size is 10 seqs
find . -size +4k -ls | sort -rk7 | wc -l    #same as above, but I had to count lines between 4520 and 4000 and subtract from wc
#-----
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Next, we must parse MEME outputs
Can generally scan logo png's; this is a good way to get a feel for the data
txt output is easy to look at
xml output is meant for parsing
	use this
meme gives a regular expression of motif
	EX: [AT]ATTACG[ACG]G
		<regular_expression> // regex // </regular_expression>
meme output gives both position frequency and weight matrix
	EX: if A appears at a position 100% of the time, then it gets a score of >300. If a C appears 0% of the time, then it gets a score of < -1100
		<scores> // <alphabet_matrix> // <alphabet_array> // matrix // </alphabet_array> // <alphabet_array> // matrix // </alphabet_array> // <alphabet_array> // .... 
	
First R script: Get consensus motif
#-----
getConsensusSeq = function(xml_data){
  lseq_evalues = list()                                                       #initiate list
  len = length(xml_data$motifs)                                               #get number of motifs
  for(i in 1:len){                                                            #interate through that number
    consensus_seq = as.character(xml_data$motifs[[i]]$.attrs[2])              #get consensus sequence; located in motifs[1:len] then the 2nd attribute
    e_value = as.character(xml_data$motifs[[i]]$.attrs[9])                    #get e_value; located in motifs[1:len] then the 9th attribute
    seq_evalue = c(consensus_seq, e_value)                                    #concatenate the consensus and e_value
    lseq_evalues[[i]] = seq_evalue                                            #add them to a list for storage
  }
  return(lseq_evalues)                                                        #return a list, which should have 5 tuples
}

#MAIN
directory = "/N/dc2/scratch/tlicknac/All_Aurelias_MEME_Results/"                                                      #location of meme outputs
meme_files = list.files(directory, recursive=F)                                                                       #List all subdirectories containing meme outputs

firstOne = T                                                                                                          #Used to initialize data frame 
final_dataframe = 0                                                                                                   #^

for(subdir in meme_files){
  cat("Working on file: ", subdir, "\n")
  meme = paste(directory, subdir, "/meme.xml", sep="")                                                                #Concatenate path to file name
  data = xmlParse(meme)                                                                                               #Get xml file
  xml_data = xmlToList(data)                                                                                          #Convert xml format to an R list
  #Get Consensus Sequence
  lseq_evalues = getConsensusSeq(xml_data)                                                                            #Function to get list of tuples: each tuple is consensus sequence and e_value
  df_seq_evalues = data.frame(matrix(unlist(lseq_evalues), nrow=length(lseq_evalues), byrow=T), stringsAsFactors=F)   #convert the list to a df
  colnames(df_seq_evalues) = c("motif", "e_value")                                                                    #Give the df colnames
  if(firstOne==T){                                                                                                    #Our strategy initiates final df using the first motif in the dir/
    final_dataframe = df_seq_evalues                                                                                  #fina_dataframe will now have 5 occupied rows
    firstOne = F                                                                                                      #set this boolean to false so we can continue appending to final_dataframe
  } else {
    final_dataframe = rbind(final_dataframe, df_seq_evalues)                                                          #append until completion
  }
  
  #Get AT Content
  #lAT = getATcontent(xml_data)
}
write.csv(final_dataframe, file="MEMExmlParaOrtholog.csv")
#-----
Will add to this as new data are needed. For now, consensus sequence will do.
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Now time to go and see how often these motifs hit within each of the Aurelia genomes
Interesting motifs by eye: 
	GCCCTCTTGGCCAAGTGG had an e_score of 9e^-235 and contains the palindrome CTTGGCCAAG 
	AAACCTGCAGGAGGACCT had an e_score of 4.3e^-227 and contains the palindrome CCTGCAGG ... very close to start codon
	GATCAGAGTGGCGAATGT had an e_score of 2.3e^-227 and contains an odd pattern very close to motif start site 
		paralogs either have aaaaatattt or taaaaaaata upstream ... aaaaataggt or ttaaaaaata ... close'ish to start codon ... found in pbi_114359 and pbi_11751 !
	#Im running FIMO on some of these interesting motifs... jsut to see

#Now get PWMs
#-----
getPWM = function(xml_data, subdir){
  lPWMs = list()
  len = length(xml_data$motifs$motif$scores$alphabet_matrix)
  nucl = c("A", "C", "G", "T")
  
  for(i in 1:len){
      ascore = xml_data$motifs$motif$scores$alphabet_matrix[[i]][1]$value$text
      cscore = xml_data$motifs$motif$scores$alphabet_matrix[[i]][2]$value$text
      gscore = xml_data$motifs$motif$scores$alphabet_matrix[[i]][3]$value$text
      tscore = xml_data$motifs$motif$scores$alphabet_matrix[[i]][4]$value$text
      motif_df = t(data.frame(c(ascore, cscore, gscore, tscore)))
      colnames(motif_df) = nucl
      motif_file = paste(subdir, i, sep="_")
      lPWMs[[motif_file]] = motif_df 
  }
  return(lPWMs)
}
#MAIN 
directory = "/N/dc2/scratch/tlicknac/All_Aurelias_MEME_Results/"                                                      #location of meme outputs
meme_files = list.files(directory, recursive=F)                                                                       #List all subdirectories containing meme outputs

firstOne = T                                                                                                          #Used to initialize data frame 
final_dataframe = 0                                                                                                   #^

for(subdir in meme_files){
  cat("Working on file: ", subdir, "\n")
  meme = paste(directory, subdir, "/meme.xml", sep="")                                                                #Concatenate path to file name
  data = xmlParse(meme)                                                                                               #Get xml file
  xml_data = xmlToList(data)                                                                                          #Convert xml format to an R list
  #Get PWM in List()
  lPWMs = getPWM(xml_data, subdir)                                                                                    #Function to return list of data frames of PWMs
  df_PWMs = data.frame(matrix(unlist(lPWMs), nrow=length(lPWMs), byrow=T), stringsAsFactors=F, row.names=NULL)
  colnames(df_PWMs) = c("A", "C", "G", "T")
  row.names(df_PWMs) = NULL
  filename = paste("/N/dc2/scratch/tlicknac/All_Aurelias_PWMs/", subdir, "_PWM", ".tab", sep="")
  cat("Writing to file: ", filename, "\n")
  write.csv(df_PWMs, file=filename)
}
+-----
Now we have 16587 .tab files containins PWMs, most of length 18
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
These files proved difficult to work with due to the large sizes and inflated e_values for motifs
I, therefore, reran MEME with motifs set to 6-12. This is more like the size of a TFBS and will allow for quicker parsing of files
To confirm which size is preferred, I wrote a script to parse MEME outputs for motifs of size 5-18 and of size 6-12

Rscript:
#-----
install.packages("XML")
library("XML")
#directory = "/N/dc2/scratch/tlicknac/12nt_MEME_Results/"                                                      #location of meme outputs
directory = "/N/dc2/scratch/tlicknac/All_Aurelias_MEME_Results/"
meme_files = list.files(directory, recursive=F)                                                               #List all subdirectories containing meme outputs
v_evalues = c()

for(subdir in meme_files){
  meme = paste(directory, subdir, "/meme.xml", sep="")                                                                #Concatenate path to file name
  data = xmlParse(meme)                                                                                               #Get xml file
  xml_data = xmlToList(data)                                                                                          #Convert xml format to an R list
  
  for(i in 1:length(xml_data$motifs)){
    evalue = as.numeric(xml_data$motifs[[i]]$.attrs[9])
    v_evalues = append(v_evalues, evalue)
  }
}
summary(v_evalues)
hist(v_evalues)
#-----
I can now look at distributions and determine which parameters are easy to work with

#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#Jeff wrote me a C++ script that will scan the genome and assign scores to each position base don the PWM
#This will allow us to visualize the distribution of scores and determine which regions of the genome are enriched for these signatures
#Can eventually use annotation to associate high score regions with gene function
